{
 "metadata": {
  "name": "",
  "signature": "sha256:9ce307aa0ff6a7d080281b4fa4583cbd9f9bc5cd5d2c9d4508c4d739745fc2a7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lab 1\n",
      "\n",
      "## Introduction\n",
      "This is a basic introduction to IPython and pandas functionality. <a href=\"http://pandas.pydata.org/\">Pandas</a> (Python Data Analysis Library) \"is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\" It (pandas) provides <a href=\"http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe\">dataframe</a> functionality for reading/accessing/manipulating data in memory. You can think of a data frame as a table of indexed values.\n",
      "\n",
      "What you're currently looking at is an IPython Notebook, this acts as a way to interactively use the python interpreter as well as a way to display graphs/charts/images/markdown along with code. IPython is commonly used in scientific computing due to its flexibility. Much more information is available on the <a href='http://ipython.org/'>IPython</a> website.\n",
      "\n",
      "Often data is stored in files, and the first goal is to get that information off of disk and into a dataframe. Since we're working with limited resources in this VM we'll have to use samples of some of the files. Don't worry though, the same techniques apply if you're not sampling the files for exploration.\n",
      "\n",
      "## Tip\n",
      "If you ever want to know the various keyboard shortcuts, just click on a (non-code) cell or the text \"In []\" to the left of the cell, and press the *H* key. Or select *Help* from the menu above, and then *Keyboard Shortcuts*.\n",
      "___"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercises\n",
      "\n",
      "### File sampling\n",
      "First off, let's take a look at a log file generated from <a href=\"http://www.bro.og/\">Bro</a> this log is similar to netflow logs as well. However, this log file is rather large and doesn't fit in memory.\n",
      "\n",
      "As part of the first exercise, figure out what setting the variable **sample_percent** should be in order to read in between 200k and 300k worth of (randomly selected) lines from the file. Change the variable, after doing that either click the *play* button above (it's the arrow) or hit the *[Shift]+[Enter]* keys as the same time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "logfile = 'conn.log'\n",
      "sample_percent = .01\n",
      "num_lines = sum(1 for line in open(logfile))\n",
      "slines = set(sorted(random.sample(xrange(num_lines), int(num_lines * sample_percent))))\n",
      "print \"%s lines in %s, using a sample of %s lines\" %(num_lines, logfile, len(slines))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### File Creation\n",
      "Awesome! Now that you have a subset of lines to work with, let's write them to another file so we'll have something to practice reading in. Simply hit *[Shift]+[Enter]* below to run the code in the cell and create a new file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outfile = 'conn_sample.log'\n",
      "f = open(outfile, 'w+')\n",
      "i = open(logfile, 'r+')\n",
      "linecount = 0\n",
      "for line in i:\n",
      "    if linecount in slines:\n",
      "        f.write(line)\n",
      "    linecount += 1\n",
      "f.close()\n",
      "i.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### File Input (CSV)\n",
      "This next cell does a couple of things, first it imports pandas so we can create a dataframe, and then it reads our newly created file from above into memory. You can see the separator is specified to \"\\t\" because Bro produces tab-delimited files by default. In this case we've also specified what we should call the columns in the dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "conn_df = pd.read_csv(outfile, sep=\"\\t\", header=None, names=['ts','uid','id.orig_h','id.orig_p','id.resp_h','id.resp_p','proto','service','duration','orig_bytes','resp_bytes','conn_state','local_orig','missed_bytes','history','orig_pkts','orig_ip_bytes','resp_pkts','resp_ip_bytes','tunnel_parents','threat','sample'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Verifying Input\n",
      "Now (in theory) the contents of the file should be in a nicely laid-out dataframe.\n",
      "\n",
      "For this next exercise, experiment with calling the **head()** and **tail()** method to see the values at the beginning and end of the dataframe. You can also pass a number to **head()** and **tail()** to specify the number of lines you want to see. Remember to click *play* or press *[Shift]+[Enter]* to execute the code in the cell after you change it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Summarization\n",
      "Now create a new cell below this one. This can be accomplished by clicking on this cell once, and then clicking the *+* icon towards the top or selecting *Insert* from above and then selecting *Insert Cell Below*. After creating the new cell, it's time to learn about the **describe()** method that can be called on dataframes. This will give you a numeric summarization of all columns that contain numbers.\n",
      "\n",
      "Try it out!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Types\n",
      "Wait a second, isn't the tx column supposed to be a timestamp? Perhaps this column would be better suited as a time data type vs. a number.\n",
      "\n",
      "Run the cell below to see what type of information Python stored in each column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Converting Column Types\n",
      "Time to change the ts column to a datetime object! The cell below will accomplish that by using a simple function provided called *to_datetime()*. The cell below runs this function on the ts column (what should be a time stamp), and then re-assigns this column back to the dataframe in the same place. A new timestamp column could have been added to the dataframe as well so both the float value and the datetime object columns are present.\n",
      "\n",
      "Run the cell below to convert the column type."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime\n",
      "conn_df['ts'] = [datetime.fromtimestamp(float(date)) for date in conn_df['ts'].values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Value Exploration\n",
      "Verify that the conversion was successful. What is the datatype of the column now?\n",
      "\n",
      "Scroll back up the page and note where you ran the **describe()** function. You'll see under the threat and sample columns there is likely the value of *NaN*. This stands for Not a Number and is a special value assigned to empty column values. There are a few ways to explore what values a column has. Two of these are **value_counts()** and **unique()**. \n",
      "\n",
      "Try them below on different columns. You can create new cells or if you want to get more than the last command worth of output you can put a print statement in front. \n",
      "\n",
      "What happens when you run them on a column with IPs (*id.orig_h, id.resp_h*)? What about sample or threat?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df['sample'].unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Remove Columns\n",
      "Another useful operation on a dataframe is removing and adding columns.  Since the threat and sample columns contain only *NaNs*, we can safely remove them and not impact any analysis that may be performed. \n",
      "\n",
      "Below the sample column is removed (dropped), add a similar line to drop the *threat* column and use a method from above to verify they are no longer in the dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df.drop('sample', axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Can you think of other columns to remove? Select a few and remove them as well. What does your dataframe look like now? (Insert additional cells as needed)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df.drop('threat', axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Row Selection\n",
      "\n",
      "You can use column values to select rows from the dataframes (and even only view specific columns). First, select all rows that contain *SSL* traffic by running the cell below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn_df[conn_df['service'] == 'ssl'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we can assign that result to a dataframe, and then look at all all the *SSL* connections that happen over ports other than 443."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ssl_df = conn_df[conn_df['service'] == 'ssl']\n",
      "ssl_df[ssl_df['id.resp_p'] != 443].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see the individual column selections above eg: *conn_df['service']*, and *ssl_df['id.resp_p']* respectively. You can use these to view output of specific columns. \n",
      "\n",
      "For example, run the cell below to see all the individual values of originator bytes associated with a *SSL* connection over port 443."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ssl_df[ssl_df['id.resp_p'] == 443][['orig_bytes','proto']].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Final Exercise\n",
      "Use all of the techniques above to display the unique ports and originator IPs (bonus points for the number of connections of each) associated with all *HTTP* connections **NOT** over port 80."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df = conn_df[conn_df['service'] == 'http']\n",
      "print http_df[http_df['id.resp_p'] != 80]['id.resp_p'].unique()\n",
      "print http_df[http_df['id.resp_p'] != 80]['id.orig_h'].unique()\n",
      "print len(http_df[http_df['id.resp_p'] != 80]['id.orig_h'].tolist())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
