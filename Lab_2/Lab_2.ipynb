{
 "metadata": {
  "name": "",
  "signature": "sha256:07f1250410d997c0e0c4f4c222283b13aee9623461a8009e0eeaa5ccbbf35917"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lab 2\n",
      "\n",
      "## Introduction\n",
      "With this lab data grouping and graphing will be explored. There is always a great deal of information you can gather by grouping and comparing various columns within a dataframe. In addition for data summarization graphing is an important tool to have.\n",
      "\n",
      "HTTP data will be used for this exercise. The data was generated from various PCAPs that have been collected that contain both legitimate traffic as well as traffic relating to exploit kits. While no malicious traffic is contained within the log file there are malicious domains and URLS (it's recommended you don't visit them). While this traffic was generated by running Bro over a series of PCAPS, similar data can be obtained from various Web Proxies, this is a nice cross over example of what is possible with your own data.\n",
      "\n",
      "Some goals will be understand when the data was generated, what systems generated, high-level stats about the traffic, and the types of data transferred within the connections.\n",
      "\n",
      "___"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercises\n",
      "\n",
      "### File Input\n",
      "Using what you learned in the last lab cread in the log (csv) file provided for you.\n",
      "\n",
      "#### Hints\n",
      "* The file name is in the current directory and is called *http.log*\n",
      "* There is no header to the file\n",
      "* It's *[TAB]* seperated\n",
      "* The fields are: 'ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'trans_depth', 'method', 'host', 'uri', 'referrer', 'user_agent', 'request_body_len', 'response_body_len', 'status_code', 'status_msg', 'info_code', 'info_msg', 'filename', 'tags', 'username', 'password', 'proxied', 'orig_fuids', 'orig_mime_types', 'resp_fuids', 'resp_mime_types', 'sample'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "http_df = pd.read_csv(\"./http.log\", header=None, sep=\"\\t\", names=[])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Clean-up the timestamp\n",
      "Now that you've got the data imported, cleanup up the timestamp column *ts*. Don't forget to re-assign back to the *ts* column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the next cell the timestamp column is set to be the new index of the dataframe. By default dataframes are indexed by the row number, and by indexing by timestamp it's easier to perform various types of time series analysis. After the assignment a quick **head()** is performed, and in the output you'll see that the *ts* has moved \"down and to the left\". The new location of the *ts* heading indicates that it is now the index, and has replaced the default."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df = http_df.set_index('ts')\n",
      "http_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Selecting Based on Index Values\n",
      "\n",
      "With the default indexing in dataframes you can select elements or slices of elements based on numbers (similarly to how lists work in Python). With a time indexed dataframe various parts of dates, or whole dates, can be used to select rows.\n",
      "\n",
      "A year can be used eg: 2012, a year and month '2012-02' or a year, month and day '2012-02-20'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df['2012-02-20':'2012-02-23'][http_df.columns.tolist()[2:7]].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df['2012-02-20':'2012-02-23']['id.orig_h'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(http_df.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Time Resampling\n",
      "Time indexed information can be resampled and summarized.\n",
      "\n",
      "Below is a resampling on day *D* that will count up the number of occurrences per day. Try various date selections to get a feel for how the sampling works and how it can be used to summarize data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time\n",
      "temp_df = http_df['2012-02-20':'2012-02-25']\n",
      "temp_df.resample(\"D\", how='count').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try the resample example from above with some of the other options for resample. Replace the *D* with some other values to get different frequencies.\n",
      "\n",
      "| Alias | Description\n",
      "| ------| -----------\n",
      "| B | business day frequency\n",
      "| C | custom business day frequency (experimental)\n",
      "| D | calendar day frequency\n",
      "| W | weekly frequency\n",
      "| M | month end frequency\n",
      "| BM | business month end frequency\n",
      "| CBM | custom business month end frequency\n",
      "| MS | month start frequency\n",
      "| BMS | business month start frequency\n",
      "| CBMS | custom business month start frequency\n",
      "| Q | quarter end frequency\n",
      "| BQ | business quarter end frequency\n",
      "| QS | quarter start frequency\n",
      "| BQS | business quarter start frequency\n",
      "| A | year end frequency\n",
      "| BA | business year end frequency\n",
      "| ASyear | start frequency\n",
      "| BAS | business year start frequency\n",
      "| H | hourly frequency\n",
      "| T | minutely frequency\n",
      "| S | secondly frequency\n",
      "| L | milliseonds\n",
      "| U | microseconds\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df['2012-02-20':'2012-02-25'].resample(\"H\", how='count').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Graphing Time Series Data\n",
      "After getting a grasp on the various ways to look at time indexed data, it's useful to display it visually. With this section the same progression as above will be used.\n",
      "\n",
      "The cell below will generate a time series graph of both the request and response bodies, summed up over their timestamps."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
      "\n",
      "df = http_df[['request_body_len','response_body_len']]\n",
      "df.plot();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A small copy of the HTTP dataframe **http_df** is stored in **df** it only contains 2 columns *[request_body_len, response_body_len]*, this enables the comparison of the request and response body lengths.\n",
      "\n",
      "Below is another way to graph the resampled data. In this case the data is resampled on *month*, and when no **how** parameter is passed to **resample()** it defaults to *mean*.\n",
      "\n",
      "#### Hint\n",
      "If you're going to use anything but *'count'* as the paremeter to **how**, you need to make sure it's numeric data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resamp = df.resample(\"M\")\n",
      "resamp.plot(style='g--')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Graphing Multiple Views (Time Series)\n",
      "It's possible to graph multiple **how** methods as well. This can help identify different patterns in the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resamp = df.resample(\"M\", how=['mean', 'count', 'sum'])\n",
      "resamp.plot(subplots=True)\n",
      "resamp.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Above, the response_body_len sum really sticks out in the bottom graph, but viewing the smaller graphs above it's possible to see that it's not because of an increase in the number of requests (it's simply because more information was received, in aggregate, over all the connections).\n",
      "\n",
      "___\n",
      "\n",
      "Below, the *count* column was added for you, try doing the same type graph as above and incorporate **np.min** and **np.max** into your resampling.\n",
      "\n",
      "#### Hint\n",
      "Do not put single quotes around **np.min** or **np.max**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['count'] = 1\n",
      "df = df['count'].cumsum()\n",
      "resamp = df.resample(\"M\", how=[])\n",
      "resamp.plot(subplots=True)\n",
      "resamp.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Dataframe Grouping\n",
      "Another useful way to look at data is how different groups of values look with one another. For this pandas offers the **groupby()** command. It allows you to specify an arbitrary list of columns in your dataframe that are evaluated left-to-right in terms of grouping.\n",
      "\n",
      "The example below shows how *resp_mime_type* (filetype returned by the server) breaks down, and then per-filetype what *user_agents* requested those files. You can see the number of entries per-column per-value in the table."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df.groupby(['resp_mime_types','user_agent']).count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's also possible to select rows (as learned in Lab 1) and then do a **groupby()** to look at various sub views of the data.\n",
      "\n",
      "This looks at all rows associated with those 2 different *user_agent*s, and then shows how many entries are in the data per-user-agent per-filetype."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df[http_df['user_agent'].isin(\n",
      "    ['Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)',\n",
      "     'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)'])].groupby(['resp_mime_types','user_agent']).count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the pre-defined filetypes below to come up with a couple of interesting views on the data that involve the **groupby()** function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "executable_types = set(['application/x-dosexec', 'application/octet-stream', 'binary', 'application/vnd.ms-cab-compressed'])\n",
      "common_exploit_types = set(['application/x-java-applet','application/pdf','application/zip','application/jar','application/x-shockwave-flash'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Graphing Groupby Data\n",
      "One advantage of the **groupby()** command is being able to graph the output to get another view into the data. One popular way to do this is via a bar graph.\n",
      "\n",
      "In the next cell there are a couple of things going on. First, a column named *count* is created and every row in that column is assigned the value of 1. This creates a column that we can use pandas to sum on since it has a value of 1 for each row.\n",
      "\n",
      "In the second line, the dataframe is grouped by *resp_mime_types* and then only the *count* column is viewed/returned from the **groupby()** command. The result is then passed to the **sum()** function, this causes the sum on the *count* column, which due to the trick above has a value of 1 for each row. Combined this gets the number of files in each filetype. The result is simply plotted with **plot()**.\n",
      "\n",
      "Any surprising results? What could they possibly indicate?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df['count'] = 1\n",
      "http_df.groupby('resp_mime_types')['count'].sum().plot(kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The technique above can be used to look at the number of samples associated with each IP in dataset.\n",
      "\n",
      "What kinds of conclusions can you draw based on the graph below?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df.groupby('id.orig_h')['count'].sum().order(ascending=False).plot(kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's a lot of IP addresses! Bonus question: How many different source IP addresses are in the data set?\n",
      "\n",
      "Remember above when we said you could access elements in a dataframe that weren't indexed by a timestamp like a regular Python array? Well, it's possible to do the same with dataframes produced by **groupby()**. By sliding around the dataset below what can you learn about the IP addresses that wasn't possible to see because of the resolution of the graph above?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df.groupby('id.orig_h')['count'].sum().order(ascending=False)[10:20].plot(kind='bar')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Stacked Groupby Graphs With Bonus Colors\n",
      "Once you learn the basic bar graph, it's time to kick it up a notch by looking at the relationship between two different columns. This can be done with stacked bar charts.\n",
      "\n",
      "In this case the relationship between filetype and HTTP method can be explored. Perhaps one or two HTTP methods are more responsible for specific filetypes vs. others. Custom colors can be created with the values in the **colors** list, and passed into the graph with **color=colors**. Similar to the examples above we're using our added *count* column to get the number of things. In this example multiple tiers are used for **groupby()** since the breakdown of methods by filetype are being explored. The **unstack()** function \"expands\" the grouped columns, and **fillna(0)** fills all non-values with zero (since these won't impact the sum).\n",
      "\n",
      "What happens when you remove the custom color labels?\n",
      "\n",
      "Bonus: Create a new cell and take a look at what the dataframe looks like without the **plot()** or other commands stacked on top of one another. This is useful to do to understand the output of each function in the chain."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "colors = [(x/10.0, x/40.0, 0.75) for x in range(len(http_df['method'].unique().tolist()))]\n",
      "http_df.groupby(['resp_mime_types','method'])['count'].sum().unstack('method').fillna(0).plot(\n",
      "    color=colors, kind='bar', stacked=True, grid=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Final Exercise\n",
      "The final challenge is using all the techniques from above to create a stacked bar chart that shows: only for destination ports 81, 88, and 8080 how many of each HTTP method is associated with each port. The **plot()** command is present to show another way to specify different custom colors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http_df.plot(colormap='GnBu', kind='bar', stacked=True, grid=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}