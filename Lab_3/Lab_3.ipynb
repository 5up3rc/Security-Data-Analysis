{
 "metadata": {
  "name": "",
  "signature": "sha256:bc38999154088d6217bc42f5480ddf9348305b1d450ed62b2967fdf95dd066d7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Lab 3\n",
      "\n",
      "## Introduction\n",
      "Since the previous labs have provided a (hopefully) good foundation in the various tools that will be used, this lab will explore some of the Statistics functions available for analysis. Overall this should be a gentle introduction (or reminder) about basic statistical analysis.This lab will pick up a the dataset used in Lab 1, building on your knowledge of dataframes, this lab gives the opportunity to explore what types of functions they export for data analysis.\n",
      "\n",
      "Some goals will be how to quickly summarize data, know how to get at specific values/features of data, understand how the data looks (statistically), and how to understand the layout of the data.\n",
      "\n",
      "### Useful Terminology\n",
      "**Mean (mu)** - The average, the sum of the numbers divided by the number of numbers.\n",
      "\n",
      "**Mode** - The number that occurs most frequently.\n",
      "\n",
      "**Median** - The middle number when the numbers are sorted, or with an even number of numbers the average of the two middle numbers.\n",
      "\n",
      "**Standard Deviation (sigma)** - The dispersion from the mean. The larger the standard deviation, the more spread out the numbers are.\n",
      "\n",
      "**Variance** - How spread out the numbers are. A Variance of zero means all numbers are the same. Similar to Standard Deviation.\n",
      "___"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercises\n",
      "\n",
      "### File Input\n",
      "Using what you learned in the last lab read in the log (csv) file provided for you.\n",
      "\n",
      "#### Hints\n",
      "* The file name is in the \"../Lab 1/ directory and is called *conn_sample.log*\n",
      "* There is no header to the file\n",
      "* It's *[TAB]* separated\n",
      "* The fields are: 'ts', 'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'proto', 'service', 'duration', 'orig_bytes', 'resp_bytes', 'conn_state', 'local_orig', 'missed_bytes', 'history', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'tunnel_parents', 'threat', 'sample'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "df = pd.read_csv('../Lab 1/conn_sample.log', sep=\"\\t\", header=None, names=['ts','uid','id.orig_h','id.orig_p','id.resp_h','id.resp_p','proto','service','duration','orig_bytes','resp_bytes','conn_state','local_orig','missed_bytes','history','orig_pkts','orig_ip_bytes','resp_pkts','resp_ip_bytes','tunnel_parents','threat','sample'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After running the above cell, run this one to verify that you've got data in the dataframe, and that it looks \"correct enough\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once again time for data cleanup!\n",
      "\n",
      "The cell below will, if you remember, fill all NaN valued cells with 0. The assumption here is that if Bro didn't fill in a value it's safe to set that value to zero. After that let's see what pandas determined the columns to be."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.fillna(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### More Data Cleanup\n",
      "\n",
      "In data produced by Bro, it will often put a *-* if it can't determine a value or one wasn't seen. It's likely you saw quite a few of these in the _head()_ command above. These have a couple of different effects on the data, they can cause pandas to not recognize the column as being purely numeric and because of that it won't compute data statistics for us.\n",
      "\n",
      "\n",
      "#### Value substitution\n",
      "\n",
      "The following columns need to be cleaned up this way: *orig_bytes*, *duration*, and *resp_bytes*.\n",
      "\n",
      "It's important to understand the changes that you make to the underlying data by substituting values. First let's take a look at some of the differences, then make the changes to the rest of the columns.\n",
      "\n",
      "First, make all Bro unknowns *-* into numpy unknowns *np.nan*, and see what that does."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['orig_bytes'].apply(lambda x: np.nan if x == '-' else x).astype(float64).describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then a similar change to make all Bro unknowns *-* into zeros, and check the output. \n",
      "\n",
      "What are some of the differences?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['orig_bytes'].apply(lambda x: 0 if x == '-' else x).astype(float64).describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pick one method, come up with your justification, and do the assignment for all the columns listed above. This can be done using a lambda function inside the **apply()** function. A lambda (function) is an anonymous function or one that is not bound to a specific name.\n",
      "\n",
      "A partial sample has been provided."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Remove un-needed columns\n",
      "\n",
      "The columns: *ts*, *uid*, *proto*, *service*, *conn_state*, *local_orig*, *history*, *tunnel_parents*, *threat*, *sample* aren't needed for this lab. Let's get rid of them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.drop([], axis=1, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Change column types\n",
      "\n",
      "Once again, in order to do analysis, columns should be set to the correct data type.\n",
      "\n",
      "Use the information/examples above to set orig_pkts, resp_pkts, and missed_bytes to *float64* and id.orig_p and id.resp_p to *object*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Last but not least, The values of (empty) can creep into the data as well (it was seen in orig_ip_bytes and resp_ip_bytes), substitute these out for your chosen value above. Also, because later on we'll do some division, set all zeros to **np.nan** in the *resp_ip_bytes* column.\n",
      "\n",
      "Make sure to verify that all your changes have held! \n",
      "\n",
      "*Hint: use the dtypes property*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature Engineering for More Stats!\n",
      "\n",
      "A simple exercise on how you can combine (now 2 numeric) features to create yet another numeric feature that can give you more insight into the data.\n",
      "\n",
      "You can perform mathematical operations on columns and assign them to a new column. Run the cell below to see how it's done, and check out some of the initial values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['out_in_ratio'] = df['orig_ip_bytes']/df['resp_ip_bytes']\n",
      "df['out_in_ratio'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Statistical Summarization\n",
      "\n",
      "As we've explored before, the **describe()** function can be used to summarize all the numerical columns in a dataframe. What happens run this is run on our our modified (and nicely cleaned up) dataframe?\n",
      "\n",
      "Did the newly created column appear as well? Anything interesting about it?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are specific functions that allow for computing the various values one at a time. \n",
      "\n",
      "Try computing the Standard Deviation of *orig_ip_bytes* using the **std()** function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.orig_ip_bytes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try computing the Variance of *orig_ip_bytes* using the **var()** function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.orig_ip_bytes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What were the results? Why do you think that's the case?\n",
      "\n",
      "*Hint: <a href=\"http://en.wikipedia.org/wiki/Standard_deviation#Basic_examples\">Wikipedia</a> has a great example of how to computer the Standard Deviation, and remember the variance is just the standard deviation squared*\n",
      "\n",
      "Below the scipy stats module can be used to compute the mode. Any surprises with the result?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats.mstats import mode\n",
      "f = lambda x: mode(x, axis=None)[0]\n",
      "#[value, count] returned by mode()\n",
      "mode(df.orig_ip_bytes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Box Plots\n",
      "\n",
      "Also known as box whisker plots, these can be used to get a good feel for how distributed the data looks. By default the box will cover the upper and lower quartiles (eg. the 25th - 75th percentile), and a red line will be at the 50th percentile. Whiskers (lines) will extend out to show the rest of the data, with (occasionally) filler points to show outliers.\n",
      "\n",
      "Here's how to create a simple boxplot so summarize the column that was added above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.boxplot(column='orig_ip_bytes')\n",
      "plt.ylabel('Out-In Byte Ratio')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Slicing data\n",
      "\n",
      "It's possible to run these functions on slices or sub-selections of the data.\n",
      "\n",
      "Below, what happens when you run the **describe()** function on the set of numbers in *orig_ip_bytes* that are less than 200?\n",
      "\n",
      "What about if you pass the option of **percentiles=[.3,.5,.7]** to the **describe()** function?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.orig_ip_bytes < 200]['orig_ip_bytes'].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Box plots on on slices\n",
      "\n",
      "Run the **boxplot()** function on the *orig_ip_bytes* column, after selecting all of the values from *orig_ip_bytes* that are less than 200 (like above). \n",
      "\n",
      "How does the plot look different from the one above?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Distribution\n",
      "\n",
      "It's useful to know the layout of your data for several reasons. One of them is due to some of the underlying assumptions some algorithms make on having continuous values. Or perhaps the data follows a Gaussian (normal) distribution. Using some of the techniques and functions from above you can begin to see how the data might be laid out. However, it's usful to compare it to known data sets (that follow a specific distribution).\n",
      "\n",
      "The following examples are based on some really nice code that The Glowing Python put together, that we've hacked up to suit our specific use case.\n",
      "\n",
      "In the first example, the numbers in the *orig_ip_bytes* are scaled (recentered around the mean), and with scikit learn (more on this later) the mean is 0 as well as the unit variance. This is a common cleaning step for Machine Learning algorithms. The scaled numbers are then compared to a randomly generated list of numbers that have the same number of numbers, and are bounded by the same min and max. The list of generated values is also computed with a given standard deviation and mean, as well as the defaults (to show how close the generated list is to \"ideal\". Both samples are compared against the numbers in scaled version of *orig_ip_bytes*.\n",
      "\n",
      "What happens to the graph when you remove **scale()** from around the **df.orig_ip_bytes.tolist()** section?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# original code from: http://glowingpython.blogspot.com/2012/07/distribution-fitting-with-scipy.html\n",
      "from scipy.stats import norm\n",
      "from numpy import linspace\n",
      "from pylab import plot,show,hist,figure,title\n",
      "from sklearn.preprocessing import scale\n",
      "\n",
      "samp = scale(df.orig_ip_bytes.tolist())\n",
      "\n",
      "param = norm.fit(samp) # distribution fitting\n",
      "\n",
      "# now, param[0] and param[1] are the mean and \n",
      "# the standard deviation of the fitted distribution\n",
      "x = linspace(min(samp),max(samp),len(samp))\n",
      "# fitted distribution\n",
      "pdf_fitted = norm.pdf(x,loc=param[0],scale=param[1])\n",
      "# original distribution\n",
      "pdf = norm.pdf(x)\n",
      "\n",
      "title('Normal distribution vs. Bytes')\n",
      "plot(x,pdf_fitted,'r-')\n",
      "plot(x,pdf,'b-')\n",
      "hist(samp,normed=1,alpha=.3)\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Same as above, except only looking at the first 100 entries in the list (to get a prettier graph).\n",
      "\n",
      "Do you get a better insight into what happens when you remove **scale()**? What happens?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samp = scale(df.orig_ip_bytes.tolist()[:100])\n",
      "\n",
      "param = norm.fit(samp) # distribution fitting\n",
      "\n",
      "# now, param[0] and param[1] are the mean and \n",
      "# the standard deviation of the fitted distribution\n",
      "x = linspace(min(samp),max(samp),len(samp))\n",
      "# fitted distribution\n",
      "pdf_fitted = norm.pdf(x,loc=param[0],scale=param[1])\n",
      "# original distribution\n",
      "pdf = norm.pdf(x)\n",
      "\n",
      "title('Normal distribution vs. Bytes')\n",
      "plot(x,pdf_fitted,'r-')\n",
      "plot(x,pdf,'b-')\n",
      "hist(samp,normed=1,alpha=.3)\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### More Data\n",
      "\n",
      "Run through the exercises above (up until the Box Plot section) on the full list of numbers in the *orig_ip_bytes* column. \n",
      "\n",
      "What are some of the differences? How good was the random sample that was taken in the first lab?\n",
      "\n",
      "*Hint: the file you want to read in is \"./orig_ip_bytes.log\". This file only contains one column, so take that into account when reading the file in. Also, no need to add the out_in_ratio columns since the other columns are present*\n",
      "\n",
      "However, before you begin there's one last thing that will be useful to know. IPython supports cell magic functions. You can get a list of them by creating a cell and executing **%lsmagic** in it. \n",
      "\n",
      "First create a new cell and run *%reset out* in it (don't forget to hit 'y'). This will clear all the output, and free up a bit of memory for this next set.\n",
      "\n",
      "Since this is a bigger dataset don't worry when some of the steps require waiting for a couple of minutes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lsmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}